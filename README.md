# Evaluating-LLMs-for-Framing-Sensitivity

This repository contains a dataset designed to evaluate the sensitivity of Large Language Models (LLMs) to different linguistic "framing" effects. The study includes 50 base items, each expanded into 6 framing variants, totaling 300 test cases.

## Dataset Structure
The project is organized into three primary components:

1. **Base Dataset** (Dataset_Items.docx): Contains the 50 original base items. Includes the 6 specific framing variants for each item.
2. **Experimental Input** (Shuffled Dataset Prompted to Model.xlsx): The randomized/shuffled version of the full dataset that was fed into the models to prevent order bias.
3. **Model Outputs** (output_of_models.xlsx): The raw and processed responses from the four models tested.
